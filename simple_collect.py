#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ ë…¼ë¬¸ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
ì¦‰ì‹œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  PDFë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
"""

import requests
import json
import time
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def collect_papers():
    """ë…¼ë¬¸ ìˆ˜ì§‘ ë° PDF ë‹¤ìš´ë¡œë“œ"""
    from datetime import datetime
    from pathlib import Path
    
    # ì‹¤í–‰ ì‹œê°„ ê¸°ì¤€ í´ë” ìƒì„±
    current_time = datetime.now()
    time_folder = current_time.strftime('%Y%m%d_%H%M%S')
    
    # ì‹œê°„ë³„ í´ë” ìƒì„±
    papers_dir = Path("papers")
    time_papers_dir = papers_dir / time_folder
    time_papers_dir.mkdir(parents=True, exist_ok=True)
    
    server_url = "http://localhost:8001"
    session = requests.Session()
    
    logging.info(f"ğŸ“ ì €ì¥ í´ë”: {time_folder}")
    logging.info(f"ğŸ“‚ í´ë” ìƒì„± ì™„ë£Œ: {time_papers_dir}")
    
    # í‚¤ì›Œë“œë³„ ì†ŒìŠ¤ ì„¤ì •
    keyword_sources = {
        # ğŸ§¬ ìƒëª…ê³¼í•™/ì˜í•™ (PubMed + arXiv)
        "cancer research": "all",
        "drug discovery": "all", 
        "genomics": "all",
        "neuroscience": "all",
        
        # ğŸŒ ì§€êµ¬ê³¼í•™/í™˜ê²½ (PubMed + arXiv)
        "geology": "all",
        "climate change": "all",
        "environmental science": "all",
        
        # ğŸ”¬ ë¬¼ë¦¬í•™/í™”í•™ (arXiv ìœ„ì£¼)
        "quantum physics": "arxiv",
        "astrophysics": "arxiv",
        "biochemistry": "all",
        
        # ğŸ“ ìˆ˜í•™ (arXiv ìœ„ì£¼)
        "mathematical analysis": "arxiv",
        "statistics": "all",
        "optimization": "arxiv",
        
        # âš¡ ì „ê¸°/ì „ìê³µí•™ (arXiv ìœ„ì£¼)
        "electrical engineering": "arxiv",
        "robotics": "arxiv",
        "semiconductor physics": "arxiv",
        
        # ğŸ¨ ì˜ˆìˆ /ë””ìì¸ (arXiv ìœ„ì£¼)
        "computer graphics": "arxiv",
        "virtual reality": "arxiv",
        "human-computer interaction": "arxiv",
        
        # ğŸ—ï¸ ê±´ì¶•/í† ëª© (arXiv ìœ„ì£¼)
        "architecture": "arxiv",
        "civil engineering": "arxiv",
        "structural engineering": "arxiv",
        
        # ğŸ’° ê²½ì œ/ê¸ˆìœµ (arXiv ìœ„ì£¼)
        "financial economics": "arxiv",
        "behavioral economics": "arxiv",
        "risk management": "arxiv",
        
        # ğŸ§  ì‹¬ë¦¬í•™/ì‚¬íšŒí•™ (PubMed + arXiv)
        "cognitive psychology": "all",
        "social psychology": "all",
        "sociology": "all",
        
        # ğŸ“š êµìœ¡/ì–¸ì–´í•™ (arXiv ìœ„ì£¼)
        "educational technology": "arxiv",
        "linguistics": "arxiv",
        "cognitive science": "arxiv",
        
        # ğŸ¥ ì˜ë£Œê¸°ê¸°/ë°”ì´ì˜¤ë©”ë””ì»¬ (PubMed + arXiv)
        "biomedical engineering": "all",
        "medical devices": "all",
        "bioinformatics": "all",
        
        # ğŸŒ± ë†ì—…/ì‹í’ˆê³¼í•™ (PubMed + arXiv)
        "agricultural science": "all",
        "food science": "all",
        "plant biology": "all",
        
        # ğŸ”’ ë³´ì•ˆ/ì‚¬ì´ë²„ë³´ì•ˆ (arXiv ìœ„ì£¼)
        "cybersecurity": "arxiv",
        "cryptography": "arxiv",
        "network security": "arxiv"
    }
    
    total_collected = 0
    total_downloaded = 0
    
    logging.info("=" * 60)
    logging.info("ê°„ë‹¨í•œ ë…¼ë¬¸ ìˆ˜ì§‘ ì‹œì‘")
    logging.info("=" * 60)
    
    for i, (keyword, source) in enumerate(keyword_sources.items(), 1):
        logging.info(f"ì§„í–‰ë¥ : {i}/{len(keyword_sources)} - '{keyword}' ì²˜ë¦¬ ì¤‘... (ì†ŒìŠ¤: {source})")
        
        try:
            # ë…¼ë¬¸ ê²€ìƒ‰
            response = session.post(f"{server_url}/search_papers", json={
                "query": keyword,
                "max_results": 8,  # ê° í‚¤ì›Œë“œë‹¹ 8ê°œì”©
                "source": source  # í‚¤ì›Œë“œë³„ ì†ŒìŠ¤ ì„¤ì •
            }, timeout=60)
            
            if response.status_code == 200:
                papers = response.json()
                logging.info(f"'{keyword}': {len(papers)}ê°œ ë…¼ë¬¸ ìˆ˜ì§‘")
                total_collected += len(papers)
                
                # PDF ë‹¤ìš´ë¡œë“œ
                downloaded_count = 0
                for paper in papers:
                    if paper.get('pdf_url'):
                        try:
                            download_response = session.post(f"{server_url}/download_paper", 
                                                           params={"paper_url": paper['url'], "time_folder": time_folder}, timeout=60)
                            
                            if download_response.status_code == 200:
                                result = download_response.json()
                                if result.get('success'):
                                    logging.info(f"  ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {result.get('filename', 'N/A')}")
                                    downloaded_count += 1
                                    total_downloaded += 1
                                else:
                                    error_msg = result.get('error', 'Unknown error')
                                    if 'too long' in error_msg.lower():
                                        logging.info(f"  â­ï¸ í˜ì´ì§€ ìˆ˜ ì´ˆê³¼ë¡œ ê±´ë„ˆëœ€: {error_msg}")
                                    else:
                                        logging.warning(f"  âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {error_msg}")
                            
                        except Exception as e:
                            logging.warning(f"  âŒ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
                    
                    # ë‹¤ìš´ë¡œë“œ ê°„ ì§€ì—°
                    time.sleep(1)
                
                logging.info(f"'{keyword}': {downloaded_count}ê°œ PDF ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                
            else:
                logging.error(f"'{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨: {response.status_code}")
            
            # í‚¤ì›Œë“œ ê°„ ì§€ì—°
            if i < len(keyword_sources):
                time.sleep(2)
                
        except Exception as e:
            logging.error(f"'{keyword}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    logging.info("=" * 60)
    logging.info(f"ìˆ˜ì§‘ ì™„ë£Œ: ì´ {total_collected}ê°œ ë…¼ë¬¸ ìˆ˜ì§‘, {total_downloaded}ê°œ PDF ë‹¤ìš´ë¡œë“œ")
    logging.info(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {time_papers_dir}")
    logging.info("=" * 60)

if __name__ == "__main__":
    collect_papers() 